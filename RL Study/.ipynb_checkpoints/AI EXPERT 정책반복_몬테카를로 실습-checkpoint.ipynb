{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê·¸ë¦¼ê·¸ë¦¬ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_v_table_small(v_table, env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+----------\"*env.reward.shape[1])\n",
    "        print(\"|\", end=\"\")\n",
    "        for j in range(env.reward.shape[1]):\n",
    "            print(\"{0:8.2f}  |\".format(v_table[i,j]),end=\"\")\n",
    "        print()\n",
    "    print(\"+----------\"*env.reward.shape[1])\n",
    "\n",
    "# V table ê·¸ë¦¬ê¸°    \n",
    "def show_v_table(v_table, env):    \n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "                if k==1:\n",
    "                        print(\"   {0:8.2f}      |\".format(v_table[i,j]),end=\"\")\n",
    "                if k==2:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")\n",
    "    \n",
    "# Q table ê·¸ë¦¬ê¸°\n",
    "def show_q_table(q_table,env):\n",
    "    for i in range(env.reward.shape[0]):\n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    print(\"{0:10.2f}       |\".format(q_table[i,j,0]),end=\"\")\n",
    "                if k==1:\n",
    "                    print(\"{0:6.2f}    {1:6.2f} |\".format(q_table[i,j,3],q_table[i,j,1]),end=\"\")\n",
    "                if k==2:\n",
    "                    print(\"{0:10.2f}       |\".format(q_table[i,j,2]),end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")\n",
    "    \n",
    "\n",
    "# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n",
    "def show_q_table_arrow(q_table,env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    if np.max(q[i,j,:]) == q[i,j,0]:\n",
    "                        print(\"        â†‘       |\",end=\"\")\n",
    "                    else:\n",
    "                        print(\"                 |\",end=\"\")\n",
    "                if k==1:                    \n",
    "                    if np.max(q[i,j,:]) == q[i,j,1] and np.max(q[i,j,:]) == q[i,j,3]:\n",
    "                        print(\"      â†  â†’     |\",end=\"\")\n",
    "                    elif np.max(q[i,j,:]) == q[i,j,1]:\n",
    "                        print(\"          â†’     |\",end=\"\")\n",
    "                    elif np.max(q[i,j,:]) == q[i,j,3]:\n",
    "                        print(\"      â†         |\",end=\"\")\n",
    "                    else:\n",
    "                        print(\"                 |\",end=\"\")\n",
    "                if k==2:\n",
    "                    if np.max(q[i,j,:]) == q[i,j,2]:\n",
    "                        print(\"        â†“       |\",end=\"\")\n",
    "                    else:\n",
    "                        print(\"                 |\",end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")    \n",
    "    \n",
    "# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n",
    "def show_policy_small(policy,env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+----------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        print(\"|\", end=\"\")\n",
    "        for j in range(env.reward.shape[1]):\n",
    "            if env.reward_list1[i][j] == \"road\":\n",
    "                if policy[i,j] == 0:\n",
    "                    print(\"   â†‘     |\",end=\"\")\n",
    "                elif policy[i,j] == 1:\n",
    "                    print(\"   â†’     |\",end=\"\")\n",
    "                elif policy[i,j] == 2:\n",
    "                    print(\"   â†“     |\",end=\"\")\n",
    "                elif policy[i,j] == 3:\n",
    "                    print(\"   â†     |\",end=\"\")\n",
    "            else:\n",
    "                print(\"          |\",end=\"\")\n",
    "        print()\n",
    "    print(\"+----------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")\n",
    "    \n",
    "# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n",
    "def show_policy(policy,env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "                if k==1:\n",
    "                    if policy[i,j] == 0:\n",
    "                        print(\"      â†‘         |\",end=\"\")\n",
    "                    elif policy[i,j] == 1:\n",
    "                        print(\"      â†’         |\",end=\"\")\n",
    "                    elif policy[i,j] == 2:\n",
    "                        print(\"      â†“         |\",end=\"\")\n",
    "                    elif policy[i,j] == 3:\n",
    "                        print(\"      â†         |\",end=\"\")\n",
    "                if k==2:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \n",
    "    # 1. í–‰ë™ì— ë”°ë¥¸ ì—ì´ì „íŠ¸ì˜ ì¢Œí‘œ ì´ë™(ìœ„, ì˜¤ë¥¸ìª½, ì•„ë˜, ì™¼ìª½) \n",
    "    action = np.array([[-1,0],[0,1],[1,0],[0,-1]])\n",
    "    \n",
    "    # 2. ê° í–‰ë™ë³„ ì„ íƒí™•ë¥ \n",
    "    select_action_pr = np.array([0.25,0.25,0.25,0.25])\n",
    "    \n",
    "    # 3. ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° ìœ„ì¹˜ ì €ì¥\n",
    "    def __init__(self):\n",
    "        self.pos = (0,0)\n",
    "    \n",
    "    # 4. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ì €ì¥\n",
    "    def set_pos(self,position):\n",
    "        self.pos = position\n",
    "        return self.pos\n",
    "    \n",
    "    # 5. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    def get_pos(self):\n",
    "        return self.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    # 1. ë¯¸ë¡œë°–(ì ˆë²½), ê¸¸, ëª©ì ì§€ì™€ ë³´ìƒ ì„¤ì •\n",
    "    cliff = -3\n",
    "    road = -1\n",
    "    goal = 1\n",
    "    \n",
    "    # 2. ëª©ì ì§€ ì¢Œí‘œ ì„¤ì •\n",
    "    goal_position = [2,2]\n",
    "    \n",
    "    # 3. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ìˆ«ì\n",
    "    reward_list = [[road,road,road],\n",
    "                   [road,road,road],\n",
    "                   [road,road,goal]]\n",
    "    \n",
    "    # 4. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ë¬¸ì\n",
    "    reward_list1 = [[\"road\",\"road\",\"road\"],\n",
    "                    [\"road\",\"road\",\"road\"],\n",
    "                    [\"road\",\"road\",\"goal\"]]\n",
    "    \n",
    "    # 5. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ arrayë¡œ ì„¤ì •\n",
    "    def __init__(self):\n",
    "        self.reward = np.asarray(self.reward_list)    \n",
    "\n",
    "    # 6. ì„ íƒëœ ì—ì´ì „íŠ¸ì˜ í–‰ë™ ê²°ê³¼ ë°˜í™˜ (ë¯¸ë¡œë°–ì¼ ê²½ìš° ì´ì „ ì¢Œí‘œë¡œ ë‹¤ì‹œ ë³µê·€)\n",
    "    def move(self, agent, action):\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        # 6.1 í–‰ë™ì— ë”°ë¥¸ ì¢Œí‘œ êµ¬í•˜ê¸°\n",
    "        new_pos = agent.pos + agent.action[action]\n",
    "        \n",
    "        # 6.2 í˜„ì¬ì¢Œí‘œê°€ ëª©ì ì§€ ì¸ì§€í™•ì¸\n",
    "        if self.reward_list1[agent.pos[0]][agent.pos[1]] == \"goal\":\n",
    "            reward = self.goal\n",
    "            observation = agent.set_pos(agent.pos)\n",
    "            done = True\n",
    "        # 6.3 ì´ë™ í›„ ì¢Œí‘œê°€ ë¯¸ë¡œ ë°–ì¸ í™•ì¸    \n",
    "        elif new_pos[0] < 0 or new_pos[0] >= self.reward.shape[0] or new_pos[1] < 0 or new_pos[1] >= self.reward.shape[1]:\n",
    "            reward = self.cliff\n",
    "            observation = agent.set_pos(agent.pos)\n",
    "            done = True\n",
    "        # 6.4 ì´ë™ í›„ ì¢Œí‘œê°€ ê¸¸ì´ë¼ë©´\n",
    "        else:\n",
    "            observation = agent.set_pos(new_pos)\n",
    "            reward = self.reward[observation[0],observation[1]]\n",
    "            \n",
    "        return observation, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì •ì±… í‰ê°€, ì •ì±… ê°œì„ \n",
    "\n",
    "ì—¬ê¸°ì„œ policy ë³€ìˆ˜ëŠ” ê° ìƒíƒœì— ëŒ€í•˜ì—¬ ì–´ë– í•œ í–‰ë™ì„ ì·¨í•  ì§€ ì €ì¥í•˜ëŠ” í–‰ë ¬ë¡œ ì •ì˜í•˜ì˜€ë‹¤.\n",
    "\n",
    "0, 1, 2, 3 = ìœ„, ì˜¤ë¥¸ìª½, ì•„ë˜, ì™¼ìª½\n",
    "\n",
    "ì˜ˆ:\n",
    "\n",
    "policy[0, 0] = 1 ì˜ ëœ» : ìƒíƒœ (0, 0) ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™í•˜ê² ë‹¤\n",
    "\n",
    "policy[1, 2] = 3 ì˜ ëœ» : ìƒíƒœ (1, 2) ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ì´ë™í•˜ê²Œ í•˜ê² ë‹¤.\n",
    "\n",
    "ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ìë©´ policy[i, j] = a ë¼ëŠ” ëœ»ì€\n",
    "\n",
    "$$\\pi(a|s_{ij}) = 1, \\pi(a'|s_{ij}) = 0\\text{  }(a'\\in A, a'\\neq a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì •ì±…í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V table ê°±ì‹  í•¨ìˆ˜\n",
    "def policy_evalution(env, agent, v_table, policy):\n",
    "    gamma = 0.9\n",
    "    while(True):\n",
    "        # Î”â†0\n",
    "        delta = 0\n",
    "        #  vâ†ğ‘‰(ğ‘ )\n",
    "        temp_v = copy.deepcopy(v_table)\n",
    "        # ëª¨ë“  ğ‘ âˆˆğ‘†ì— ëŒ€í•´ :\n",
    "        for i in range(env.reward.shape[0]):\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                # ì—ì´ì „íŠ¸ë¥¼ ì§€ì •ëœ ì¢Œí‘œì— ìœ„ì¹˜ì‹œí‚¨í›„ ê°€ì¹˜í•¨ìˆ˜ë¥¼ ê³„ì‚°\n",
    "                agent.set_pos([i,j])\n",
    "                # í˜„ì¬ ì •ì±…ì˜ í–‰ë™ì„ ì„ íƒ\n",
    "                action = policy[i,j]\n",
    "                observation, reward, done = env.move(agent, action)\n",
    "                v_table[i,j] = reward + gamma * v_table[observation[0],observation[1]]\n",
    "        # âˆ†â†maxâ¡(âˆ†,|vâˆ’ğ‘‰(ğ‘ )|)\n",
    "        # ê³„ì‚°ì „ê³¼ ê³„ì‚°í›„ì˜ ê°€ì¹˜ì˜ ì°¨ì´ë¥¼ ê³„ì‚°\n",
    "        delta = np.max([delta, np.max(np.abs(temp_v-v_table))])  \n",
    "                \n",
    "        # 7. âˆ† <ğœƒê°€ ì‘ì€ ì–‘ìˆ˜ ì¼ ë•Œê¹Œì§€ ë°˜ë³µ\n",
    "        if delta < 0.000001:\n",
    "            break\n",
    "    return v_table, delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì •ì±…ê°œì„ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy ê°±ì‹  í•¨ìˆ˜\n",
    "def policy_improvement(env, agent, v_table, policy):\n",
    "\n",
    "    gamma = 0.9  \n",
    "    \n",
    "    # policyStable â† true \n",
    "    policyStable = True\n",
    "\n",
    "    # ëª¨ë“  sâˆˆSì— ëŒ€í•´ï¼š\n",
    "    for i in range(env.reward.shape[0]):\n",
    "        for j in range(env.reward.shape[1]):            \n",
    "            # ğ‘œğ‘™ğ‘‘âˆ’ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›â†Ï€(s) \n",
    "            old_action = policy[i,j]            \n",
    "            # ê°€ëŠ¥í•œ í–‰ë™ì¤‘ ìµœëŒ“ê°’ì„ ê°€ì§€ëŠ” í–‰ë™ì„ ì„ íƒ\n",
    "            temp_action = 0\n",
    "            temp_value =  -1e+10           \n",
    "            for action in range(len(agent.action)):\n",
    "                agent.set_pos([i,j])\n",
    "                observation, reward, done = env.move(agent,action)\n",
    "                if temp_value < reward + gamma * v_table[observation[0],observation[1]]:\n",
    "                    temp_action = action\n",
    "                    temp_value = reward + gamma * v_table[observation[0],observation[1]]\n",
    "            # ë§Œì•½ ğ‘œğ‘™ğ‘‘âˆ’ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\"â‰ Ï€(s)\"ë¼ë©´ï¼Œ \"policyStable â† False\" \n",
    "            # old-actionê³¼ ìƒˆë¡œìš´ actionì´ ë‹¤ë¥¸ì§€ ì²´í¬\n",
    "            if old_action != temp_action :\n",
    "                policyStable = False\n",
    "            policy[i,j] = temp_action\n",
    "    return policy, policyStable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì •ì±… ë°˜ë³µ (ì •ì±… í‰ê°€ <=> ì •ì±… ê°œì„ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random V(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.55      |       0.72      |       0.60      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.54      |       0.42      |       0.65      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.44      |       0.89      |       0.96      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "Initial random Policy Ï€0(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†“         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†         |      â†         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†‘         |      â†’         |      â†’         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "start policy iteration\n",
      "\n",
      "VÏ€0(S) delta = 0.0000009713\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|     -28.00      |       6.20      |       8.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|     -30.00      |     -28.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|     -28.00      |      10.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "policy Ï€1(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†‘         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†‘         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "VÏ€1(S) delta = 0.0000002328\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       4.58      |       6.20      |       8.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       3.12      |       8.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       8.00      |      10.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "policy Ï€2(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†‘         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "VÏ€2(S) delta = 0.0000001885\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       4.58      |       6.20      |       8.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       6.20      |       8.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       8.00      |      10.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "policy Ï€3(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†‘         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "total_time = 0.017938852310180664\n"
     ]
    }
   ],
   "source": [
    "# ì •ì±… ë°˜ë³µ\n",
    "# í™˜ê²½ê³¼ ì—ì´ì „íŠ¸ì— ëŒ€í•œ ì´ˆê¸° ì„¤ì •\n",
    "np.random.seed(0)\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "# 1. ì´ˆê¸°í™”\n",
    "# ëª¨ë“  ğ‘ âˆˆğ‘†ì— ëŒ€í•´ ğ‘‰(ğ‘ )âˆˆğ‘…ê³¼ Ï€(ğ‘ )âˆˆğ´(ğ‘ )ë¥¼ ì„ì˜ë¡œ ì„¤ì •\n",
    "\n",
    "#shape : [h, w]\n",
    "v_table =  np.random.rand(env.reward.shape[0], env.reward.shape[1])\n",
    "\n",
    "#shape : [h, w]\n",
    "#ê°’ : í•´ë‹¹ ìƒíƒœì—ì„œ ì–´ë– í•œ í–‰ë™ì„ ì·¨í•  ê²ƒì¸ì§€ ë‚˜íƒ€ë‚´ëŠ” ì •ìˆ˜\n",
    "policy = np.random.randint(0, 4,(env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "print(\"Initial random V(S)\")\n",
    "show_v_table(np.round(v_table,2),env)\n",
    "print()\n",
    "print(\"Initial random Policy Ï€0(S)\")\n",
    "show_policy(policy,env)\n",
    "print(\"start policy iteration\")\n",
    "\n",
    "# ì‹œì‘ ì‹œê°„ì„ ë³€ìˆ˜ì— ì €ì¥\n",
    "start_time = time.time()\n",
    "\n",
    "max_iter_number = 20000\n",
    "for iter_number in range(max_iter_number):\n",
    "    \n",
    "    # 2.ì •ì±…í‰ê°€\n",
    "    v_table, delta = policy_evalution(env, agent, v_table, policy)\n",
    "\n",
    "    # ì •ì±… í‰ê°€ í›„ ê²°ê³¼ í‘œì‹œ                                            \n",
    "    print(\"\")\n",
    "    print(\"VÏ€{0:}(S) delta = {1:.10f}\".format(iter_number,delta))\n",
    "    show_v_table(np.round(v_table,2),env)\n",
    "    print()    \n",
    "    \n",
    "    \n",
    "    # 3.ì •ì±…ê°œì„ \n",
    "    policy, policyStable = policy_improvement(env, agent, v_table, policy)\n",
    "\n",
    "    # policy ë³€í™” ì €ì¥\n",
    "    print(\"policy Ï€{}(S)\".format(iter_number+1))\n",
    "    show_policy(policy,env)\n",
    "    # í•˜ë‚˜ë¼ë„ old-actionê³¼ ìƒˆë¡œìš´ actionì´ ë‹¤ë¥´ë‹¤ë©´ '2. ì •ì±…í‰ê°€'ë¥¼ ë°˜ë³µ\n",
    "    if(policyStable == True):\n",
    "        break\n",
    "\n",
    "        \n",
    "print(\"total_time = {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì—í”¼ì†Œë“œ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(env, agent, *args, **kwargs):\n",
    "    gamma = 0.9\n",
    "    # ì—í”¼ì†Œë“œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "    episode = []\n",
    "    # ì´ì „ì— ë°©ë¬¸ì—¬ë¶€ ì²´í¬\n",
    "    \n",
    "    \n",
    "    # ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ìƒíƒœì—ì„œ ì¶œë°œí•  ìˆ˜ ìˆê²Œ ì¶œë°œì§€ì ì„ ë¬´ì‘ìœ„ë¡œ ì„¤ì •\n",
    "    i = np.random.randint(0,env.reward.shape[0])\n",
    "    j = np.random.randint(0,env.reward.shape[1])\n",
    "    agent.set_pos([i,j])    \n",
    "    \n",
    "    #ì—í”¼ì†Œë“œì˜ ìˆ˜ìµì„ ì´ˆê¸°í™”\n",
    "    G = 0\n",
    "    \n",
    "    #ê°ì‡„ìœ¨ì˜ ì§€ìˆ˜\n",
    "    step = 0\n",
    "    max_step = 100\n",
    "    \n",
    "    # ì—í”¼ì†Œë“œ ìƒì„±\n",
    "    for k in range(max_step):\n",
    "        pos = agent.get_pos()            \n",
    "        action = np.random.randint(0,len(agent.action))            \n",
    "        observaetion, reward, done = env.move(agent, action)\n",
    "        #[position, action, reward, dummy_G_value = 0]\n",
    "        episode.append([pos, action, reward, 0])\n",
    "\n",
    "        # ì—í”¼ì†Œë“œê°€ ì¢…ë£Œí–ˆë‹¤ë©´ ë£¨í”„ì—ì„œ íƒˆì¶œ\n",
    "        if done == True:                \n",
    "            break\n",
    "            \n",
    "    # episode ìˆœê°„ë§ˆë‹¤ Gê°’ êµ¬í•˜ê¸°\n",
    "    for ep_i in range(len(episode)-1, -1, -1):\n",
    "        G = G*gamma + episode[ep_i][2] # + reward\n",
    "        episode[ep_i][3] = G\n",
    "            \n",
    "    return i, j, G, episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===episode 1===\n",
      "[0, 1]  a: up reward: -3\n",
      "total reward: -3\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -3.0\n",
      "===episode 2===\n",
      "[1, 1]  a: down reward: -1\n",
      "[2 1]  a: up reward: -1\n",
      "[1 1]  a: left reward: -1\n",
      "[1 0]  a: down reward: -1\n",
      "[2 0]  a: up reward: -1\n",
      "[1 0]  a: up reward: -1\n",
      "[0 0]  a: up reward: -3\n",
      "total reward: -9\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -6.2799130000000005\n",
      "===episode 3===\n",
      "[2, 1]  a: down reward: -3\n",
      "total reward: -3\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -3.0\n",
      "===episode 4===\n",
      "[2, 0]  a: right reward: -1\n",
      "[2 1]  a: right reward: 1\n",
      "[2 2]  a: right reward: 1\n",
      "total reward: 1\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  0.71\n",
      "===episode 5===\n",
      "[1, 0]  a: right reward: -1\n",
      "[1 1]  a: up reward: -1\n",
      "[0 1]  a: left reward: -1\n",
      "[0 0]  a: up reward: -3\n",
      "total reward: -6\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -4.897\n",
      "===episode 6===\n",
      "[1, 2]  a: left reward: -1\n",
      "[1 1]  a: left reward: -1\n",
      "[1 0]  a: up reward: -1\n",
      "[0 0]  a: down reward: -1\n",
      "[1 0]  a: left reward: -3\n",
      "total reward: -7\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -5.4073\n",
      "===episode 7===\n",
      "[0, 1]  a: left reward: -1\n",
      "[0 0]  a: right reward: -1\n",
      "[0 1]  a: left reward: -1\n",
      "[0 0]  a: left reward: -3\n",
      "total reward: -6\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -4.897\n",
      "===episode 8===\n",
      "[2, 0]  a: right reward: -1\n",
      "[2 1]  a: right reward: 1\n",
      "[2 2]  a: right reward: 1\n",
      "total reward: 1\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  0.71\n",
      "===episode 9===\n",
      "[0, 2]  a: up reward: -3\n",
      "total reward: -3\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -3.0\n",
      "===episode 10===\n",
      "[2, 2]  a: left reward: 1\n",
      "total reward: 1\n",
      "G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  1.0\n"
     ]
    }
   ],
   "source": [
    "#ì—í”¼ì†Œë“œ ìƒì„± ì‹¤í—˜\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in range(10):\n",
    "  print(\"===episode %d===\" % (i+1))\n",
    "  _, _, G, episode = generate_episode(env, agent, True)\n",
    "  total_reward = 0\n",
    "  for where, action, reward, G_s in episode:\n",
    "    print(where,\"\", \"a:\", [\"up\", \"right\", \"down\", \"left\"][action], \"reward:\", reward)\n",
    "    total_reward += reward\n",
    "  print(\"total reward:\", total_reward)\n",
    "  print(\"G(ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜): \", G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-visit and Every-Visit MC Prediction\n",
    "\n",
    "#### -- \"í”„ë¡œê·¸ë˜ë¨¸ë¥¼ ìœ„í•œ ê°•í™”í•™ìŠµ\" ì—ëŠ” ì—†ëŠ” ë‚´ìš© --\n",
    "\n",
    "First-visit MCëŠ” (ì—í”¼ì†Œë“œ ë‚´) ìƒíƒœ sì˜ ì²« ë°©ë¬¸ì‹œì˜ ë°˜í™˜ê°’ë§Œ ê³ ë ¤í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "Every-visit MCëŠ” (ì—í”¼ì†Œë“œ ë‚´) ìƒíƒœ sì˜ ëª¨ë“  ë°©ë¬¸ì˜ ë°˜í™˜ê°’ì„ ê³ ë ¤í•˜ëŠ” ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start first visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:03<00:00, 25901.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.80      |      -3.99      |      -3.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.01      |      -3.89      |      -2.42      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.42      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_start_count(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   11302.00      |   11148.00      |   11021.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   11077.00      |   11027.00      |   11109.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   11151.00      |   11075.00      |   11090.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_success_pr(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.04      |       0.09      |       0.10      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.09      |       0.20      |       0.33      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.10      |       0.33      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "start every visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:04<00:00, 24727.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.81      |      -4.01      |      -3.45      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.02      |      -3.91      |      -2.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.44      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_start_count(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   22405.00      |   22257.00      |   22302.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   22296.00      |   22070.00      |   22076.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   22137.00      |   22175.00      |   22282.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_success_pr(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.04      |       0.09      |       0.10      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.09      |       0.21      |       0.33      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.10      |       0.33      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# first-visit MC and every-visit MC prediction\n",
    "np.random.seed(0)\n",
    "# í™˜ê²½, ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "# ì„ì˜ì˜ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ğ‘‰\n",
    "v_table = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ìƒíƒœë³„ë¡œ ì—í”¼ì†Œë“œ ì¶œë°œíšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n",
    "v_start = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ìƒíƒœë³„ë¡œ ë„ì°©ì§€ì  ë„ì°©íšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n",
    "v_success = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )â†ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  sâˆˆğ‘†ì— ëŒ€í•´)\n",
    "Return_s = [[[] for j in range(env.reward.shape[1])] for i in range(env.reward.shape[0])]\n",
    "\n",
    "# ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ë¥¼ ì§€ì •\n",
    "max_episode = 100000\n",
    "\n",
    "# first visit ë¥¼ ì‚¬ìš©í• ì§€ every visitë¥¼ ì‚¬ìš©í•  ì§€ ê²°ì •\n",
    "# first_visit = True : first visit\n",
    "# first_visit = False : every visit\n",
    "\n",
    "for first_visit in [True, False]:\n",
    "    if first_visit:\n",
    "        print(\"start first visit MC\")\n",
    "    else : \n",
    "        print(\"start every visit MC\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "    for epi in tqdm(range(max_episode)):\n",
    "\n",
    "        i,j,G,episode = generate_episode(env, agent)\n",
    "\n",
    "        visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "        v_start[i,j] += 1\n",
    "        for where, action, reward, G_s in episode:\n",
    "            s_i, s_j = where\n",
    "            if first_visit and visit[s_i][s_j] == 1:\n",
    "                continue\n",
    "            visit[s_i][s_j] = 1\n",
    "            Return_s[s_i][s_j].append(G_s)\n",
    "\n",
    "\n",
    "        ## ìˆ˜ìµ ğºë¥¼ ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )ì— ì¶”ê°€(append)\n",
    "        #Return_s[i][j].append(G)\n",
    "        #\n",
    "        ## ì—í”¼ì†Œë“œ ë°œìƒ íšŸìˆ˜ ê³„ì‚°\n",
    "        #episode_count = len(Return_s[i][j])\n",
    "        ## ìƒíƒœë³„ ë°œìƒí•œ ìˆ˜ìµì˜ ì´í•© ê³„ì‚°\n",
    "        #total_G = np.sum(Return_s[i][j])\n",
    "        ## ìƒíƒœë³„ ë°œìƒí•œ ìˆ˜ìµì˜ í‰ê·  ê³„ì‚°\n",
    "        #v_table[i,j] = total_G / episode_count\n",
    "\n",
    "        # ë„ì°©ì§€ì ì— ë„ì°©(reward = 1)í–ˆëŠ”ì§€ ì²´í¬    \n",
    "        # episode[-1][2] : ì—í”¼ì†Œë“œ ë§ˆì§€ë§‰ ìƒíƒœì˜ ë³´ìƒ\n",
    "        if episode[-1][2] == 1:\n",
    "            v_success[i,j] += 1\n",
    "\n",
    "\n",
    "    # ì—í”¼ì†Œë“œ ì¶œë°œ íšŸìˆ˜ ì €ì¥ \n",
    "    for i in range(env.reward.shape[0]):\n",
    "        for j in range(env.reward.shape[1]):\n",
    "            visit_count = len(Return_s[i][j])\n",
    "            total_G = np.sum(Return_s[i][j])\n",
    "            v_table[i,j] = total_G / visit_count\n",
    "\n",
    "    print(\"V(s)\")\n",
    "    show_v_table(np.round(v_table,2),env)\n",
    "    print(\"V_start_count(s)\")\n",
    "    show_v_table(np.round(v_start,2),env)\n",
    "    print(\"V_success_pr(s)\")\n",
    "    show_v_table(np.round(v_success/v_start,2),env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental mean (ì¦ë¶„ í‰ê· ) ì„ ì´ìš©í•˜ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ Prediction ì•Œê³ ë¦¬ì¦˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start first visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:05<00:00, 17666.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.80      |      -3.99      |      -3.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.01      |      -3.89      |      -2.42      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.42      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "start every visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:06<00:00, 15752.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.81      |      -4.01      |      -3.45      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.02      |      -3.91      |      -2.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.44      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Incremental mean ì„ ì´ìš©í•˜ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ Prediction ì•Œê³ ë¦¬ì¦˜\n",
    "np.random.seed(0)\n",
    "# í™˜ê²½, ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "# ì„ì˜ì˜ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ğ‘‰\n",
    "v_table = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ì¶”ê°€\n",
    "# ìƒíƒœë¥¼ ë°©ë¬¸í•œ íšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n",
    "v_visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ì‚­ì œ\n",
    "# # ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )â†ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  sâˆˆğ‘†ì— ëŒ€í•´) : \n",
    "# Return_s = [[[] for j in range(env.reward.shape[1])] for i in range(env.reward.shape[0])]\n",
    "\n",
    "# ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ì™€ ì—í”¼ì†Œë“œ ìµœëŒ€ ê¸¸ì´ì§€ì •\n",
    "max_episode = 100000\n",
    "\n",
    "# first visitì„ ì‚¬ìš©í• ì§€ every visitì„ ì‚¬ìš©í•  ì§€ ê²°ì •\n",
    "# first_visit = True : first visit\n",
    "# first_visit = False : every visit\n",
    "for first_visit in [True, False]:\n",
    "    if first_visit:\n",
    "        print(\"start first visit MC\")\n",
    "    else : \n",
    "        print(\"start every visit MC\")\n",
    "    print()\n",
    "\n",
    "    for epi in tqdm(range(max_episode)):\n",
    "\n",
    "        i,j,G,episode = generate_episode(env, agent, first_visit)\n",
    "\n",
    "        visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "        v_start[i,j] += 1\n",
    "        for where, action, reward, G_s in episode:\n",
    "            s_i, s_j = where\n",
    "            if first_visit and visit[s_i][s_j] == 1:\n",
    "                continue\n",
    "            visit[s_i][s_j] = 1\n",
    "\n",
    "            v_visit[s_i,s_j] += 1\n",
    "            v_table[s_i,s_j] += 1 / v_visit[s_i,s_j] * (G_s - v_table[s_i,s_j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"V(s)\")\n",
    "    show_v_table(np.round(v_table,2),env)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë“  ì½”ë“œë¥¼ ì‹¤í–‰í•´ ë³´ê³  ì¶œë ¥ ê²°ê³¼ë¥¼ ì–»ì–´ë³´ì."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
