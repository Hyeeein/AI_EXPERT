{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê·¸ë¦¼ê·¸ë¦¬ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_v_table_small(v_table, env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+----------\"*env.reward.shape[1])\n",
    "        print(\"|\", end=\"\")\n",
    "        for j in range(env.reward.shape[1]):\n",
    "            print(\"{0:8.2f}  |\".format(v_table[i,j]),end=\"\")\n",
    "        print()\n",
    "    print(\"+----------\"*env.reward.shape[1])\n",
    "\n",
    "# V table ê·¸ë¦¬ê¸°    \n",
    "def show_v_table(v_table, env):    \n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "                if k==1:\n",
    "                        print(\"   {0:8.2f}      |\".format(v_table[i,j]),end=\"\")\n",
    "                if k==2:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")\n",
    "    \n",
    "# Q table ê·¸ë¦¬ê¸°\n",
    "def show_q_table(q_table,env):\n",
    "    for i in range(env.reward.shape[0]):\n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    print(\"{0:10.2f}       |\".format(q_table[i,j,0]),end=\"\")\n",
    "                if k==1:\n",
    "                    print(\"{0:6.2f}    {1:6.2f} |\".format(q_table[i,j,3],q_table[i,j,1]),end=\"\")\n",
    "                if k==2:\n",
    "                    print(\"{0:10.2f}       |\".format(q_table[i,j,2]),end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")\n",
    "    \n",
    "\n",
    "# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n",
    "def show_q_table_arrow(q_table,env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    if np.max(q[i,j,:]) == q[i,j,0]:\n",
    "                        print(\"        â†‘       |\",end=\"\")\n",
    "                    else:\n",
    "                        print(\"                 |\",end=\"\")\n",
    "                if k==1:                    \n",
    "                    if np.max(q[i,j,:]) == q[i,j,1] and np.max(q[i,j,:]) == q[i,j,3]:\n",
    "                        print(\"      â†  â†’     |\",end=\"\")\n",
    "                    elif np.max(q[i,j,:]) == q[i,j,1]:\n",
    "                        print(\"          â†’     |\",end=\"\")\n",
    "                    elif np.max(q[i,j,:]) == q[i,j,3]:\n",
    "                        print(\"      â†         |\",end=\"\")\n",
    "                    else:\n",
    "                        print(\"                 |\",end=\"\")\n",
    "                if k==2:\n",
    "                    if np.max(q[i,j,:]) == q[i,j,2]:\n",
    "                        print(\"        â†“       |\",end=\"\")\n",
    "                    else:\n",
    "                        print(\"                 |\",end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")    \n",
    "    \n",
    "# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n",
    "def show_policy_small(policy,env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+----------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        print(\"|\", end=\"\")\n",
    "        for j in range(env.reward.shape[1]):\n",
    "            if env.reward_list1[i][j] == \"road\":\n",
    "                if policy[i,j] == 0:\n",
    "                    print(\"   â†‘     |\",end=\"\")\n",
    "                elif policy[i,j] == 1:\n",
    "                    print(\"   â†’     |\",end=\"\")\n",
    "                elif policy[i,j] == 2:\n",
    "                    print(\"   â†“     |\",end=\"\")\n",
    "                elif policy[i,j] == 3:\n",
    "                    print(\"   â†     |\",end=\"\")\n",
    "            else:\n",
    "                print(\"          |\",end=\"\")\n",
    "        print()\n",
    "    print(\"+----------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")\n",
    "    \n",
    "# ì •ì±… policy í™”ì‚´í‘œë¡œ ê·¸ë¦¬ê¸°\n",
    "def show_policy(policy,env):\n",
    "    for i in range(env.reward.shape[0]):        \n",
    "        print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "        print(\"+\")\n",
    "        for k in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                if k==0:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "                if k==1:\n",
    "                    if policy[i,j] == 0:\n",
    "                        print(\"      â†‘         |\",end=\"\")\n",
    "                    elif policy[i,j] == 1:\n",
    "                        print(\"      â†’         |\",end=\"\")\n",
    "                    elif policy[i,j] == 2:\n",
    "                        print(\"      â†“         |\",end=\"\")\n",
    "                    elif policy[i,j] == 3:\n",
    "                        print(\"      â†         |\",end=\"\")\n",
    "                if k==2:\n",
    "                    print(\"                 |\",end=\"\")\n",
    "            print()\n",
    "    print(\"+-----------------\"*env.reward.shape[1],end=\"\")\n",
    "    print(\"+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \n",
    "    # 1. í–‰ë™ì— ë”°ë¥¸ ì—ì´ì „íŠ¸ì˜ ì¢Œí‘œ ì´ë™(ìœ„, ì˜¤ë¥¸ìª½, ì•„ë˜, ì™¼ìª½) \n",
    "    action = np.array([[-1,0],[0,1],[1,0],[0,-1]])\n",
    "    \n",
    "    # 2. ê° í–‰ë™ë³„ ì„ íƒí™•ë¥ \n",
    "    select_action_pr = np.array([0.25,0.25,0.25,0.25])\n",
    "    \n",
    "    # 3. ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° ìœ„ì¹˜ ì €ì¥\n",
    "    def __init__(self):\n",
    "        self.pos = (0,0)\n",
    "    \n",
    "    # 4. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ì €ì¥\n",
    "    def set_pos(self,position):\n",
    "        self.pos = position\n",
    "        return self.pos\n",
    "    \n",
    "    # 5. ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    def get_pos(self):\n",
    "        return self.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    # 1. ë¯¸ë¡œë°–(ì ˆë²½), ê¸¸, ëª©ì ì§€ì™€ ë³´ìƒ ì„¤ì •\n",
    "    cliff = -3\n",
    "    road = -1\n",
    "    goal = 1\n",
    "    \n",
    "    # 2. ëª©ì ì§€ ì¢Œí‘œ ì„¤ì •\n",
    "    goal_position = [2,2]\n",
    "    \n",
    "    # 3. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ìˆ«ì\n",
    "    reward_list = [[road,road,road],\n",
    "                   [road,road,road],\n",
    "                   [road,road,goal]]\n",
    "    \n",
    "    # 4. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ ë¬¸ì\n",
    "    reward_list1 = [[\"road\",\"road\",\"road\"],\n",
    "                    [\"road\",\"road\",\"road\"],\n",
    "                    [\"road\",\"road\",\"goal\"]]\n",
    "    \n",
    "    # 5. ë³´ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ arrayë¡œ ì„¤ì •\n",
    "    def __init__(self):\n",
    "        self.reward = np.asarray(self.reward_list)    \n",
    "\n",
    "    # 6. ì„ íƒëœ ì—ì´ì „íŠ¸ì˜ í–‰ë™ ê²°ê³¼ ë°˜í™˜ (ë¯¸ë¡œë°–ì¼ ê²½ìš° ì´ì „ ì¢Œí‘œë¡œ ë‹¤ì‹œ ë³µê·€)\n",
    "    def move(self, agent, action):\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        # 6.1 í–‰ë™ì— ë”°ë¥¸ ì¢Œí‘œ êµ¬í•˜ê¸°\n",
    "        new_pos = agent.pos + agent.action[action]\n",
    "        \n",
    "        # 6.2 í˜„ì¬ì¢Œí‘œê°€ ëª©ì ì§€ ì¸ì§€í™•ì¸\n",
    "        if self.reward_list1[agent.pos[0]][agent.pos[1]] == \"goal\":\n",
    "            reward = self.goal\n",
    "            observation = agent.set_pos(agent.pos)\n",
    "            done = True\n",
    "        # 6.3 ì´ë™ í›„ ì¢Œí‘œê°€ ë¯¸ë¡œ ë°–ì¸ í™•ì¸    \n",
    "        elif new_pos[0] < 0 or new_pos[0] >= self.reward.shape[0] or new_pos[1] < 0 or new_pos[1] >= self.reward.shape[1]:\n",
    "            reward = self.cliff\n",
    "            observation = agent.set_pos(agent.pos)\n",
    "            done = True\n",
    "        # 6.4 ì´ë™ í›„ ì¢Œí‘œê°€ ê¸¸ì´ë¼ë©´\n",
    "        else:\n",
    "            observation = agent.set_pos(new_pos)\n",
    "            reward = self.reward[observation[0],observation[1]]\n",
    "            \n",
    "        return observation, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì •ì±… í‰ê°€, ì •ì±… ê°œì„ \n",
    "\n",
    "ì—¬ê¸°ì„œ policy ë³€ìˆ˜ëŠ” ê° ìƒíƒœì— ëŒ€í•˜ì—¬ ì–´ë– í•œ í–‰ë™ì„ ì·¨í•  ì§€ ì €ì¥í•˜ëŠ” í–‰ë ¬ë¡œ ì •ì˜í•˜ì˜€ë‹¤.\n",
    "\n",
    "0, 1, 2, 3 = ìœ„, ì˜¤ë¥¸ìª½, ì•„ë˜, ì™¼ìª½\n",
    "\n",
    "ì˜ˆ:\n",
    "\n",
    "policy[0, 0] = 1 ì˜ ëœ» : ìƒíƒœ (0, 0) ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™í•˜ê² ë‹¤\n",
    "\n",
    "policy[1, 2] = 3 ì˜ ëœ» : ìƒíƒœ (1, 2) ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ì´ë™í•˜ê²Œ í•˜ê² ë‹¤.\n",
    "\n",
    "ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ìë©´ policy[i, j] = a ë¼ëŠ” ëœ»ì€\n",
    "\n",
    "$$\\pi(a|s_{ij}) = 1, \\pi(a'|s_{ij}) = 0\\text{  }(a'\\in A, a'\\neq a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°˜ë³µ ì •ì±… í‰ê°€\n",
    "\n",
    "\n",
    "* êµ¬í˜„ ë°©ë²•\n",
    "\n",
    "\n",
    "1. ìƒíƒœê°€ì¹˜ë¥¼ ì €ì¥í•˜ëŠ” ìƒíƒœê°€ì¹˜ í…Œì´ë¸”ì„ 2ê°œ ì´ìš©í•˜ëŠ” ê²ƒ: ì´ì „ì— ê³„ì‚°ëœ ìƒíƒœê°€ì¹˜ë¥¼ ì´ìš©í•´ ìƒˆë¡œìš´ ìƒíƒœê°€ì¹˜ë¥¼ ê³„ì‚°í•´ì„œ ë‹¤ë¥¸ í…Œì´ë¸”ì— ì €ì¥í•˜ê³ , ì €ì¥ëœ ìƒíƒœê°€ì¹˜ í…Œì´ë¸”ì„ ì´ì „ ìƒíƒœê°€ì¹˜ê°€ ì €ì¥ëœ í…Œì´ë¸”ì— ë³µì‚¬í•˜ê³  ë‹¤ì‹œ ìƒˆë¡œìš´ ìƒíƒœê°€ì¹˜ë¥¼ ê³„ì‚°í•´ì„œ í…Œì´ë¸”ë¡œ ê³„ì‚°í•˜ëŠ” ë°©ì‹\n",
    "\n",
    "\n",
    "2. ìƒíƒœê°€ì¹˜ë¥¼ ì €ì¥í•˜ëŠ” ìƒíƒœê°€ì¹˜ í…Œì´ë¸”ì„ 1ê°œ ì´ìš©í•˜ëŠ” ê²ƒ: ë©”ëª¨ë¦¬ë¥¼ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ, kì˜ ìŠ¤í…ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë°œìƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* S: ë§ˆì§€ë§‰ ìƒíƒœë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë“  ìƒíƒœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V table ê°±ì‹  í•¨ìˆ˜\n",
    "def policy_evalution(env, agent, v_table, policy):\n",
    "    gamma = 0.9\n",
    "    \n",
    "    while(True):\n",
    "        # Î”â†0\n",
    "        delta = 0\n",
    "        \n",
    "        #  vâ†ğ‘‰(ğ‘ )\n",
    "        temp_v = copy.deepcopy(v_table)\n",
    "        \n",
    "        # ëª¨ë“  ğ‘ âˆˆğ‘†ì— ëŒ€í•´ :\n",
    "        for i in range(env.reward.shape[0]):\n",
    "            for j in range(env.reward.shape[1]):\n",
    "                \n",
    "                # ì—ì´ì „íŠ¸ë¥¼ ì§€ì •ëœ ì¢Œí‘œì— ìœ„ì¹˜ì‹œí‚¨í›„ ê°€ì¹˜í•¨ìˆ˜ë¥¼ ê³„ì‚°\n",
    "                agent.set_pos([i,j])\n",
    "                \n",
    "                # í˜„ì¬ ì •ì±…ì˜ í–‰ë™ì„ ì„ íƒ\n",
    "                action = policy[i,j]\n",
    "                observation, reward, done = env.move(agent, action)\n",
    "                v_table[i,j] = reward + gamma * v_table[observation[0],observation[1]]\n",
    "                \n",
    "        # âˆ†â†maxâ¡(âˆ†,|vâˆ’ğ‘‰(ğ‘ )|)\n",
    "        # ê³„ì‚°ì „ê³¼ ê³„ì‚°í›„ì˜ ê°€ì¹˜ì˜ ì°¨ì´ë¥¼ ê³„ì‚°\n",
    "        delta = np.max([delta, np.max(np.abs(temp_v-v_table))])  \n",
    "                \n",
    "        # 7. âˆ† <ğœƒê°€ ì‘ì€ ì–‘ìˆ˜ ì¼ ë•Œê¹Œì§€ ë°˜ë³µ\n",
    "        if delta < 0.000001:\n",
    "            break\n",
    "            \n",
    "    return v_table, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì •ì±…ê°œì„ \n",
    "\n",
    "\n",
    "* ê°œì„ : ê° ìƒíƒœì˜ ìƒíƒœê°€ì¹˜ V(s)ë¥¼ ì´ìš©í•´ ìƒˆë¡œìš´ ì •ì±…ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ê²ƒ\n",
    "\n",
    "\n",
    "* ì •ì±… ê°œì„ : ì •ì±… í‰ê°€ë¥¼ í†µí•´ ê³„ì‚°ëœ ìƒˆë¡œìš´ ìƒíƒœê°€ì¹˜ë¥¼ ì´ìš©í•´ ìµœì ì˜ í–‰ë™ì„ ì„ íƒí•˜ëŠ” ê²ƒ\n",
    "    - ìµœì ì˜ í–‰ë™: í–‰ë™ê°€ì¹˜ê°€ ê°€ì¥ í° í–‰ë™\n",
    "    - ìµœì ì˜ í–‰ë™ì„ ì„ íƒí•¨ìœ¼ë¡œì¨ í˜„ì¬ ì •ì±…ì´ ìƒˆë¡œìš´ ì •ì±…ìœ¼ë¡œ ê°œì„ ë¨\n",
    "    \n",
    "    \n",
    "* ì¦‰, ê³¼ê±°ì˜ ì •ì±…ìœ¼ë¡œ ê³„ì‚°ëœ í–‰ë™ê°€ì¹˜ì— ì˜í•´ ìƒˆë¡œìš´ ì •ì±…ìœ¼ë¡œ ê°œì„ ë˜ëŠ” ê³¼ì •ì„ 'ì •ì±… ê°œì„ 'ì´ë¼ê³  í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy ê°±ì‹  í•¨ìˆ˜\n",
    "def policy_improvement(env, agent, v_table, policy):\n",
    "\n",
    "    gamma = 0.9  \n",
    "    \n",
    "    # policyStable â† true \n",
    "    policyStable = True\n",
    "\n",
    "    # ëª¨ë“  sâˆˆSì— ëŒ€í•´ï¼š\n",
    "    for i in range(env.reward.shape[0]):\n",
    "        for j in range(env.reward.shape[1]):   \n",
    "            \n",
    "            # ğ‘œğ‘™ğ‘‘âˆ’ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›â†Ï€(s) \n",
    "            old_action = policy[i,j]          \n",
    "            \n",
    "            # ê°€ëŠ¥í•œ í–‰ë™ì¤‘ ìµœëŒ“ê°’ì„ ê°€ì§€ëŠ” í–‰ë™ì„ ì„ íƒ\n",
    "            temp_action = 0\n",
    "            temp_value =  -1e+10           \n",
    "            for action in range(len(agent.action)):\n",
    "                agent.set_pos([i,j])\n",
    "                observation, reward, done = env.move(agent,action)\n",
    "                if temp_value < reward + gamma * v_table[observation[0],observation[1]]:\n",
    "                    temp_action = action\n",
    "                    temp_value = reward + gamma * v_table[observation[0],observation[1]]\n",
    "                    \n",
    "            # ë§Œì•½ ğ‘œğ‘™ğ‘‘âˆ’ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\"â‰ Ï€(s)\"ë¼ë©´ï¼Œ \"policyStable â† False\" \n",
    "            # old-actionê³¼ ìƒˆë¡œìš´ actionì´ ë‹¤ë¥¸ì§€ ì²´í¬\n",
    "            if old_action != temp_action :\n",
    "                policyStable = False\n",
    "                \n",
    "            policy[i,j] = temp_action\n",
    "            \n",
    "    return policy, policyStable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì •ì±… ë°˜ë³µ (ì •ì±… í‰ê°€ <=> ì •ì±… ê°œì„ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prediction: ìƒˆë¡œìš´ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ê³¼ì •\n",
    "* Control : ìƒˆë¡œìš´ ì •ì±…ì„ ìƒì„±í•˜ëŠ” ê³¼ì •\n",
    "\n",
    "\n",
    "* ì •ì±… ë°˜ë³µ: Predictionê³¼ Controlì„ ë°˜ë³µí•˜ë©´ì„œ ìµœì ì˜ ê°€ì¹˜í•¨ìˆ˜ Vì™€ ìµœì ì˜ ì •ì±… Ï€ë¥¼ ì°¾ì•„ê°€ëŠ” ì•Œê³ ë¦¬ì¦˜\n",
    "    - Prediction: ì •ì±… í‰ê°€ë¥¼ ì‚¬ìš©í•´ í˜„ì¬ ì •ì±…ì„ ì´ìš©í•´ ìƒˆë¡œìš´ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ë¥¼ ê³„ì‚°\n",
    "    - Control: Predictionì—ì„œ ê³„ì‚°ëœ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ê¸°ì¡´ ì •ì±…ì„ ìƒˆë¡œìš´ ì •ì±…ìœ¼ë¡œ ê°œì„ \n",
    "    - ê³„ì† ë°˜ë³µí•˜ë‹¤ë³´ë©´, ìµœì  ê°€ì¹˜í•¨ìˆ˜ì™€ ìµœì  ì •ì±…ìœ¼ë¡œ ìˆ˜ë ´í•˜ê²Œ ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random V(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.55      |       0.72      |       0.60      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.54      |       0.42      |       0.65      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.44      |       0.89      |       0.96      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "Initial random Policy Ï€0(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†“         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†         |      â†         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†‘         |      â†’         |      â†’         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "start policy iteration\n",
      "\n",
      "VÏ€0(S) delta = 0.0000009713\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|     -28.00      |       6.20      |       8.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|     -30.00      |     -28.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|     -28.00      |      10.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "policy Ï€1(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†‘         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†‘         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "VÏ€1(S) delta = 0.0000002328\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       4.58      |       6.20      |       8.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       3.12      |       8.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       8.00      |      10.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "policy Ï€2(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†‘         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "VÏ€2(S) delta = 0.0000001885\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       4.58      |       6.20      |       8.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       6.20      |       8.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       8.00      |      10.00      |      10.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "policy Ï€3(S)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†“         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      â†’         |      â†’         |      â†‘         |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "total_time = 0.019945144653320312\n"
     ]
    }
   ],
   "source": [
    "# ì •ì±… ë°˜ë³µ\n",
    "# í™˜ê²½ê³¼ ì—ì´ì „íŠ¸ì— ëŒ€í•œ ì´ˆê¸° ì„¤ì •\n",
    "np.random.seed(0)\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "# 1. ì´ˆê¸°í™”\n",
    "# ëª¨ë“  ğ‘ âˆˆğ‘†ì— ëŒ€í•´ ğ‘‰(ğ‘ )âˆˆğ‘…ê³¼ Ï€(ğ‘ )âˆˆğ´(ğ‘ )ë¥¼ ì„ì˜ë¡œ ì„¤ì •\n",
    "\n",
    "#shape : [h, w]\n",
    "v_table =  np.random.rand(env.reward.shape[0], env.reward.shape[1])\n",
    "\n",
    "#shape : [h, w]\n",
    "#ê°’ : í•´ë‹¹ ìƒíƒœì—ì„œ ì–´ë– í•œ í–‰ë™ì„ ì·¨í•  ê²ƒì¸ì§€ ë‚˜íƒ€ë‚´ëŠ” ì •ìˆ˜\n",
    "policy = np.random.randint(0, 4,(env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "print(\"Initial random V(S)\")\n",
    "show_v_table(np.round(v_table,2),env)\n",
    "print()\n",
    "print(\"Initial random Policy Ï€0(S)\")\n",
    "show_policy(policy,env)\n",
    "print(\"start policy iteration\")\n",
    "\n",
    "# ì‹œì‘ ì‹œê°„ì„ ë³€ìˆ˜ì— ì €ì¥\n",
    "start_time = time.time()\n",
    "\n",
    "max_iter_number = 20000\n",
    "for iter_number in range(max_iter_number):\n",
    "    \n",
    "    # 2.ì •ì±…í‰ê°€\n",
    "    v_table, delta = policy_evalution(env, agent, v_table, policy)\n",
    "\n",
    "    # ì •ì±… í‰ê°€ í›„ ê²°ê³¼ í‘œì‹œ                                            \n",
    "    print(\"\")\n",
    "    print(\"VÏ€{0:}(S) delta = {1:.10f}\".format(iter_number,delta))\n",
    "    show_v_table(np.round(v_table,2),env)\n",
    "    print()    \n",
    "    \n",
    "    \n",
    "    # 3.ì •ì±…ê°œì„ \n",
    "    policy, policyStable = policy_improvement(env, agent, v_table, policy)\n",
    "\n",
    "    # policy ë³€í™” ì €ì¥\n",
    "    print(\"policy Ï€{}(S)\".format(iter_number+1))\n",
    "    show_policy(policy,env)\n",
    "    # í•˜ë‚˜ë¼ë„ old-actionê³¼ ìƒˆë¡œìš´ actionì´ ë‹¤ë¥´ë‹¤ë©´ '2. ì •ì±…í‰ê°€'ë¥¼ ë°˜ë³µ\n",
    "    if(policyStable == True):\n",
    "        break\n",
    "\n",
    "        \n",
    "print(\"total_time = {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ì´ˆê¸° ì •ì±…ì€ ëª¨ë“  ìƒíƒœì—ì„œ ìƒí•˜ì¢Œìš° ì¤‘ ì„ì˜ì˜ í–‰ë™(ë°©í–¥)ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŒ. ì €ì•¡ í‰ê°€ì—ì„œëŠ” ì´ ì´ˆê¸° ì •ì±…ì„ ì´ìš©í•´ ê° ìƒíƒœì—ì„œ í–‰ë™ì„ ì„ íƒí•˜ê³  ìƒíƒœê°€ì¹˜ë¥¼ ê³„ì‚°í•¨. ì •ì±… í‰ê°€ê°€ ëë‚˜ë©´ ì •ì±… ê°œì„ ì—ì„œëŠ” ëª¨ë“  ìƒíƒœì—ì„œ ê³„ì‚°ëœ ìƒíƒœê°€ì¹˜ë¥¼ ì´ìš©í•´ ê° ìƒíƒœì—ì„œ ìµœì ì˜ í–‰ë™ìœ¼ë¡œ êµ¬ì„±ëœ ê°œì„ ëœ ì •ì±…ì„ ê³„ì‚°. ì •ì±… ê°œì„ ê³¼ ì •ì±…í‰ê°€ë¥¼ ì •ì±…ì´ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ë°˜ë³µ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í”„ë¦¬ ì•Œê³ ë¦¬ì¦˜(Model-free algorithm)\n",
    "\n",
    "\n",
    "- ë™ì ê³„íšë²•ì—ì„œëŠ” ìš°ë¦¬ê°€ í™˜ê²½ì— ëŒ€í•œ ì •ë³´ë¥¼ ì™„ì „íˆ íŒŒì•…í•˜ê³  ìˆë‹¤ëŠ” ê°€ì •í•˜ì— ê°€ì¹˜ì™€ ì •ì±…ì„ ê³„ì‚°í–ˆìœ¼ë¯€ë¡œ, ìµœì  ê°€ì¹˜ì™€ ìµœì  ì •ì±…ì„ ê³„ì‚°í•  ìˆ˜ ìˆì—ˆìŒ. í•˜ì§€ë§Œ, ì‹¤ì œí™˜ê²½ì€ ê·¸ë ‡ì§€ ì•ŠìŒ. ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì¡°ê±´ì„ ëª¨ë‘ ì—´ê±°í•  ìˆ˜ ì—†ê³ , ê·¸ ì¡°ê±´ì— ë”°ë¥¸ í™•ë¥ ì„ ì „í˜€ ì•Œ ìˆ˜ ì—†ìŒ.\n",
    "    \n",
    "    \n",
    "- ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜: ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²• (MC), ì‹œê°„ì°¨ í•™ìŠµ (TD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•ì˜ Prediction\n",
    "\n",
    "\n",
    "- íƒìƒ‰ì ì¸ ë°©ë²•ì„ ì´ìš©í•´ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ì™€ í–‰ë™ê°€ì¹˜í•¨ìˆ˜ë¥¼ í•™ìŠµ\n",
    "\n",
    "\n",
    "- ì–´ë””ë¥¼ ì–´ë–»ê²Œ ì´ë™í•´ì•¼í•˜ëŠ”ì§€ì— ëŒ€í•œ ìƒíƒœì „ì´í™•ë¥  ì •ë³´ê°€ ì „í˜€ ì—†ìŒ. ì„ì˜ì˜ ìƒíƒœì—ì„œ ì„ì˜ì˜ ì •ì±…ì„ ì´ìš©í•´ í–‰ë™ì„ ì„ íƒí•˜ê³  ì´ë™í•˜ëŠ” ì‹œë„ë¥¼ ë¬´ìˆ˜íˆ ë°˜ë³µí•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ì´ìš©í•´ ì—ì´ì „íŠ¸ê°€ ì•Œì§€ ëª»í•˜ëŠ” í™˜ê²½ì— ëŒ€í•´ ìµœì ì˜ í–‰ë™ì„ í•™ìŠµí•˜ëŠ” ê²ƒ\n",
    "\n",
    "\n",
    "- ìˆ˜í–‰ ê³¼ì •\n",
    "    1. ë„ì°©ì§€ì ì„ ì œì™¸í•œ s0ë¶€í„° s7ê¹Œì§€ ë¯¸ë¡œì˜ ëª¨ë“  ìƒíƒœì—ì„œ ì—í”¼ì†Œë“œë¥¼ ì‹œì‘í•˜ê³ , ì—í”¼ì†Œë“œë³„ë¡œ ì–»ì€ ìˆ˜ìµ Gë¥¼ ì €ì¥\n",
    "    2. ëª¨ë“  ë‹¨ê³„ì—ì„œ í–‰ë™ì€ ê°€ëŠ¥í•œ í–‰ë™ë“¤ ì¤‘ì—ì„œ ë¬´ì‘ìœ„ë¡œ ì„ íƒ\n",
    "    3. ê·¸ë ‡ê²Œ ì§€ì •ëœ íšŸìˆ˜ në²ˆë§Œí¼(ë§ìœ¼ë©´ ë§ì„ìˆ˜ë¡ ì¢‹ìŒ) ì—í”¼ì†Œë“œê°€ ëë‚˜ë©´ ìˆ˜ìµ Gë“¤ì˜ í‰ê· ì„ ê° ìƒíƒœë§ˆë‹¤ ê³„ì‚°í•´ì„œ ê° ìƒíƒœì˜ ìƒíƒœê°€ì¹˜ë¡œ ì €ì¥\n",
    "    \n",
    "    \n",
    "- ë°©ë²•\n",
    "    1. First-visit MC : ì²« ë²ˆì§¸ë¡œ ë„ì°©í•œ ìƒíƒœì˜ ë³´ìƒë§Œì„ ì°¸ê³ í•˜ëŠ” ë°©ë²•, ì´í›„ ì¤‘ë³µëœ ìƒíƒœì˜ ë³´ìƒì€ ê³„ì‚°ì— í¬í•¨í•˜ì§€ ì•ŠìŒ\n",
    "    2. Every-visit MC : ê±°ì³ê°„ ëª¨ë“  ìƒíƒœì˜ ë³´ìƒì„ ìˆ˜ìµì— ì°¸ê³ í•˜ëŠ” ë°©ë²•\n",
    "    \n",
    "\n",
    "- ì „ì œì¡°ê±´\n",
    "    1. ëª¨ë“  ìƒíƒœì—ì„œ ì‹œì‘í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.\n",
    "    2. ì—í”¼ì†Œë“œëŠ” ë°˜ë“œì‹œ ëì´ ìˆì–´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì—í”¼ì†Œë“œ ìƒì„±\n",
    "\n",
    "\n",
    "* i, j : ì—í”¼ì†Œë“œ ì¶œë°œ ìƒíƒœ ì¢Œí‘œ\n",
    "\n",
    "\n",
    "* G : ì—í”¼ì†Œë“œì—ì„œ ì–»ì€ ìˆ˜ìµ\n",
    "\n",
    "\n",
    "* episode : ì—í”¼ì†Œë“œë¥¼ ì§„í–‰í•˜ë©´ì„œ ë°©ë¬¸ ì •ë³´ë¥¼ ì €ì¥í•œ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "\n",
    "`[ë°©ë¬¸í•œ ìƒíƒœ, ì„ íƒí•œ í–‰ë™, ì–»ì€ ë³´ìƒ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(env, agent, *args, **kwargs):\n",
    "    gamma = 0.9\n",
    "    \n",
    "    # ì—í”¼ì†Œë“œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "    episode = []\n",
    "    \n",
    "    # ì´ì „ì— ë°©ë¬¸ì—¬ë¶€ ì²´í¬\n",
    "    visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "    \n",
    "    # ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ìƒíƒœì—ì„œ ì¶œë°œí•  ìˆ˜ ìˆê²Œ ì¶œë°œì§€ì ì„ ë¬´ì‘ìœ„ë¡œ ì„¤ì •\n",
    "#     i = np.random.randint(0,env.reward.shape[0])\n",
    "#     j = np.random.randint(0,env.reward.shape[1])\n",
    "    i, j = 0, 0\n",
    "    agent.set_pos([i,j])    # ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ì €ì¥\n",
    "    \n",
    "    #ì—í”¼ì†Œë“œì˜ ìˆ˜ìµì„ ì´ˆê¸°í™”\n",
    "    G = 0\n",
    "    \n",
    "    #ê°ì‡„ìœ¨ì˜ ì§€ìˆ˜\n",
    "    step = 0\n",
    "    max_step = 100\n",
    "    \n",
    "    # ì—í”¼ì†Œë“œ ìƒì„±\n",
    "    for k in range(max_step):\n",
    "        pos = agent.get_pos()   # ì—ì´ì „íŠ¸ì˜ ìœ„ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°          \n",
    "        action = np.random.randint(0,len(agent.action))            \n",
    "        observaetion, reward, done = env.move(agent, action)  # ì„ íƒëœ ì—ì´ì „íŠ¸ì˜ í–‰ë™ê²°ê³¼ ë°˜í™˜ (ì´ë™í•œ ì¢Œí‘œ, ë³´ìƒ ê°’, ì§„í–‰ê°€ëŠ¥ ì—¬ë¶€)\n",
    "        \n",
    "        # ë°©ë¬¸ ì´ë ¥ ì €ì¥ (ìƒíƒœ, í–‰ë™, ë³´ìƒ)\n",
    "        #[position, action, reward, dummy_G_value = 0]\n",
    "        episode.append([pos, action, reward, 0])\n",
    "\n",
    "        # ì—í”¼ì†Œë“œê°€ ì¢…ë£Œí–ˆë‹¤ë©´ ë£¨í”„ì—ì„œ íƒˆì¶œ\n",
    "        if done == True:                \n",
    "            break\n",
    "            \n",
    "    # episode ìˆœê°„ë§ˆë‹¤ Gê°’ êµ¬í•˜ê¸°\n",
    "    for ep_i in range(len(episode)-1, -1, -1):\n",
    "        G = G*gamma + episode[ep_i][2] # + reward\n",
    "        episode[ep_i][3] = G\n",
    "            \n",
    "    return i, j, G, episode   # ì—í”¼ì†Œë“œ ì¶œë°œ ìƒíƒœ ì¢Œí‘œ, ìˆ˜ìµ, ë°©ë¬¸ ì •ë³´ë¥¼ ì €ì¥í•œ ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===episode 1===\n",
      "[0, 1]  a: up reward: -3\n",
      "total reward: -3\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -3.0\n",
      "\n",
      " ===episode 2===\n",
      "[1, 1]  a: down reward: -1\n",
      "[2 1]  a: up reward: -1\n",
      "[1 1]  a: left reward: -1\n",
      "[1 0]  a: down reward: -1\n",
      "[2 0]  a: up reward: -1\n",
      "[1 0]  a: up reward: -1\n",
      "[0 0]  a: up reward: -3\n",
      "total reward: -9\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -6.2799130000000005\n",
      "\n",
      " ===episode 3===\n",
      "[2, 1]  a: down reward: -3\n",
      "total reward: -3\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -3.0\n",
      "\n",
      " ===episode 4===\n",
      "[2, 0]  a: right reward: -1\n",
      "[2 1]  a: right reward: 1\n",
      "[2 2]  a: right reward: 1\n",
      "total reward: 1\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  0.71\n",
      "\n",
      " ===episode 5===\n",
      "[1, 0]  a: right reward: -1\n",
      "[1 1]  a: up reward: -1\n",
      "[0 1]  a: left reward: -1\n",
      "[0 0]  a: up reward: -3\n",
      "total reward: -6\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -4.897\n",
      "\n",
      " ===episode 6===\n",
      "[1, 2]  a: left reward: -1\n",
      "[1 1]  a: left reward: -1\n",
      "[1 0]  a: up reward: -1\n",
      "[0 0]  a: down reward: -1\n",
      "[1 0]  a: left reward: -3\n",
      "total reward: -7\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -5.4073\n",
      "\n",
      " ===episode 7===\n",
      "[0, 1]  a: left reward: -1\n",
      "[0 0]  a: right reward: -1\n",
      "[0 1]  a: left reward: -1\n",
      "[0 0]  a: left reward: -3\n",
      "total reward: -6\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -4.897\n",
      "\n",
      " ===episode 8===\n",
      "[2, 0]  a: right reward: -1\n",
      "[2 1]  a: right reward: 1\n",
      "[2 2]  a: right reward: 1\n",
      "total reward: 1\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  0.71\n",
      "\n",
      " ===episode 9===\n",
      "[0, 2]  a: up reward: -3\n",
      "total reward: -3\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  -3.0\n",
      "\n",
      " ===episode 10===\n",
      "[2, 2]  a: left reward: 1\n",
      "total reward: 1\n",
      "G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜):  1.0\n"
     ]
    }
   ],
   "source": [
    "#ì—í”¼ì†Œë“œ ìƒì„± ì‹¤í—˜\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\n ===episode %d===\" % (i+1))\n",
    "    \n",
    "    _, _, G, episode = generate_episode(env, agent, True)\n",
    "    total_reward = 0\n",
    "    \n",
    "    for where, action, reward, G_s in episode:\n",
    "        print(where,\"\", \"a:\", [\"up\", \"right\", \"down\", \"left\"][action], \"reward:\", reward)\n",
    "        total_reward += reward\n",
    "        \n",
    "    print(\"total reward:\", total_reward)\n",
    "    print(\"G (ê°ê°€ìœ¨ ì ìš©í•œ ê°€ì¹˜): \", G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-visit and Every-Visit MC Prediction\n",
    "\n",
    "#### -- \"í”„ë¡œê·¸ë˜ë¨¸ë¥¼ ìœ„í•œ ê°•í™”í•™ìŠµ\" ì—ëŠ” ì—†ëŠ” ë‚´ìš© --\n",
    "\n",
    "First-visit MCëŠ” (ì—í”¼ì†Œë“œ ë‚´) ìƒíƒœ sì˜ ì²« ë°©ë¬¸ì‹œì˜ ë°˜í™˜ê°’ë§Œ ê³ ë ¤í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "Every-visit MCëŠ” (ì—í”¼ì†Œë“œ ë‚´) ìƒíƒœ sì˜ ëª¨ë“  ë°©ë¬¸ì˜ ë°˜í™˜ê°’ì„ ê³ ë ¤í•˜ëŠ” ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start first visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:03<00:00, 25726.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.80      |      -3.99      |      -3.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.01      |      -3.89      |      -2.42      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.42      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_start_count(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   11302.00      |   11148.00      |   11021.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   11077.00      |   11027.00      |   11109.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   11151.00      |   11075.00      |   11090.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_success_pr(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.04      |       0.09      |       0.10      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.09      |       0.20      |       0.33      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.10      |       0.33      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "start every visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:04<00:00, 23708.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.81      |      -4.01      |      -3.45      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.02      |      -3.91      |      -2.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.44      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_start_count(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   22405.00      |   22257.00      |   22302.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   22296.00      |   22070.00      |   22076.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|   22137.00      |   22175.00      |   22282.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "V_success_pr(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.04      |       0.09      |       0.10      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.09      |       0.21      |       0.33      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|       0.10      |       0.33      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# first-visit MC and every-visit MC prediction\n",
    "np.random.seed(0)\n",
    "\n",
    "# í™˜ê²½, ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "# ì„ì˜ì˜ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ ğ‘‰\n",
    "v_table = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ìƒíƒœë³„ë¡œ ì—í”¼ì†Œë“œ ì¶œë°œíšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n",
    "v_start = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ìƒíƒœë³„ë¡œ ë„ì°©ì§€ì  ë„ì°©íšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n",
    "v_success = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )â†ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  sâˆˆğ‘†ì— ëŒ€í•´)\n",
    "Return_s = [[[] for j in range(env.reward.shape[1])] for i in range(env.reward.shape[0])]\n",
    "\n",
    "# ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ë¥¼ ì§€ì •\n",
    "max_episode = 100000\n",
    "\n",
    "# first visit ë¥¼ ì‚¬ìš©í• ì§€ every visitë¥¼ ì‚¬ìš©í•  ì§€ ê²°ì •\n",
    "# first_visit = True : first visit\n",
    "# first_visit = False : every visit\n",
    "\n",
    "for first_visit in [True, False]:\n",
    "    if first_visit:\n",
    "        print(\"start first visit MC\")\n",
    "    else : \n",
    "        print(\"start every visit MC\")\n",
    "    print()\n",
    "\n",
    "    for epi in tqdm(range(max_episode)):\n",
    "\n",
    "        i,j,G,episode = generate_episode(env, agent)\n",
    "\n",
    "        visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "        v_start[i,j] += 1\n",
    "        \n",
    "        for where, action, reward, G_s in episode:\n",
    "            s_i, s_j = where\n",
    "            \n",
    "            if first_visit and visit[s_i][s_j] == 1:\n",
    "                continue\n",
    "                \n",
    "            visit[s_i][s_j] = 1\n",
    "            Return_s[s_i][s_j].append(G_s)\n",
    "\n",
    "            \n",
    "        ## ìˆ˜ìµ ğºë¥¼ ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )ì— ì¶”ê°€(append)\n",
    "        # Return_s[i][j].append(G)\n",
    "        ## ì—í”¼ì†Œë“œ ë°œìƒ íšŸìˆ˜ ê³„ì‚°\n",
    "        # episode_count = len(Return_s[i][j])\n",
    "        ## ìƒíƒœë³„ ë°œìƒí•œ ìˆ˜ìµì˜ ì´í•© ê³„ì‚°\n",
    "        # total_G = np.sum(Return_s[i][j])\n",
    "        ## ìƒíƒœë³„ ë°œìƒí•œ ìˆ˜ìµì˜ í‰ê·  ê³„ì‚°\n",
    "        # v_table[i,j] = total_G / episode_count\n",
    "        # Return_length[i][j].append(len(episode))\n",
    "\n",
    "        # ë„ì°©ì§€ì ì— ë„ì°©(reward = 1)í–ˆëŠ”ì§€ ì²´í¬    \n",
    "        # episode[-1][2] : ì—í”¼ì†Œë“œ ë§ˆì§€ë§‰ ìƒíƒœì˜ ë³´ìƒ\n",
    "        if episode[-1][2] == 1:\n",
    "            v_success[i,j] += 1\n",
    "\n",
    "\n",
    "    # ì—í”¼ì†Œë“œ ì¶œë°œ íšŸìˆ˜ ì €ì¥ \n",
    "    for i in range(env.reward.shape[0]):\n",
    "        \n",
    "        for j in range(env.reward.shape[1]):\n",
    "            \n",
    "            visit_count = len(Return_s[i][j])\n",
    "            total_G = np.sum(Return_s[i][j])\n",
    "            v_table[i,j] = total_G / visit_count\n",
    "\n",
    "    print(\"V(s)\")\n",
    "    show_v_table(np.round(v_table,2),env)\n",
    "    print(\"V_start_count(s)\")\n",
    "    show_v_table(np.round(v_start,2),env)\n",
    "    print(\"V_success_pr(s)\")\n",
    "    show_v_table(np.round(v_success/v_start,2),env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ê° ìƒíƒœë“¤ì˜ ìƒíƒœê°€ì¹˜ëŠ” ë„ì°©ì§€ì ì„ í–¥í•´ ì ì  ì»¤ì§€ê³  ìˆìŒ\n",
    "    - ìƒíƒœì „ì´í™•ë¥ ì„ ëª°ë¼ë„ ìƒíƒœê°€ì¹˜ê°€ í•™ìŠµ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒë„ í™•ì¸ ê°€ëŠ¥  \n",
    "2. ì¤‘ë³µëœ ìƒíƒœê°€ ìˆì§€ë§Œ, first-visit MCì™€ Every-visit MCì˜ ìƒíƒœê°€ì¹˜ëŠ” ê±°ì˜ ë™ì¼\n",
    "3. ì—í”¼ì†Œë“œì˜ ì‹œì‘ ìƒíƒœë„ ë¬´ì‘ìœ„ë¡œ ê²°ì •í–ˆì§€ë§Œ, ê±°ì˜ ë™ì¼í•œ íšŸìˆ˜ë¡œ ê° ìƒíƒœì—ì„œ ì—í”¼ì†Œë“œê°€ ì‹œì‘í–ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ.\n",
    "4. ê° ìƒíƒœì—ì„œ ì¶œë°œí–ˆì„ ë–„, ë„ì°©ì§€ì ì— ë„ì°©í•  í™•ë¥ ì„ ë³´ë©´ ìƒíƒœê°€ì¹˜ì™€ ê°™ì´ ë„ì°©ì§€ì ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ í™•ë¥ ì´ ì»¤ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incremental mean\n",
    "\n",
    "- `ìƒˆë¡œìš´ í‰ê·  <- ì´ì „ í‰ê·  + ìŠ¤í… ì‚¬ì´ì¦ˆ X (ìƒˆë¡œìš´ ë°ì´í„° - ì´ì „ í‰ê· )`\n",
    "\n",
    "    - (ìƒˆë¡œìš´ ë°ì´í„° - ì´ì „ í‰ê· )ì´ ì–‘ìˆ˜ì´ë©´ ìƒˆë¡œìš´ í‰ê· ì€ ì¦ê°€ / ìŒìˆ˜ë©´ ê°ì†Œ\n",
    "\n",
    "\n",
    "- ê·¸ë˜ì„œ ì½”ë“œë¥¼ ìˆ˜ì •í–ˆëŠ”ë° `incremental meanì„ ì ìš©í•œ ì½”ë“œì™€ ì´ì „ ì½”ë“œì˜ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ëŠ” ë™ì¼í•¨`\n",
    "\n",
    "\n",
    "- ê²°êµ­, ì¦ë¶„ í‰ê· ì„ ì‚¬ìš©í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¤„ê³ , ìƒíƒœê°€ì¹˜í•¨ìˆ˜ë¥¼ ì—í”¼ì†Œë“œ ë‹¨ìœ„ë¡œ ê°„ë‹¨í•˜ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "\n",
    "- ëª¬í…Œì¹´ë¥¼ë¡œ ì²« ë²ˆì§¸ ì „ì œì¡°ê±´: \"ëª¨ë“  ìƒíƒœì—ì„œ ì¶œë°œí•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.\"\n",
    "    - But, ì•ì—ì„œ ì •ì˜í•œ ë¬¸ì œì²˜ëŸ¼ ì—ì´ì „íŠ¸ì˜ ì‹œì‘ì´ í•­ìƒ s0ì—ì„œ ì‹œì‘í•´ì•¼ í•˜ë©´ ì¶œë°œì§€ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ìƒíƒœì—ì„œ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ ê³„ì‚°í•  ìˆ˜ ì—†ìŒ.\n",
    "    - ì²« ì—í”¼ì†Œë“œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì„œë¸Œ ì—í”¼ì†Œë“œëŠ” ì¬ìƒì„±í•˜ì—¬, í•˜ë‚˜ì˜ ë…ë¦½ ì—í”¼ì†Œë“œë¡œ ë‹¤ë£¨ë©´ ëª¨ë“  ìƒíƒœì— ëŒ€í•´ ìƒíƒœê°€ì¹˜í•¨ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental mean (ì¦ë¶„ í‰ê· ) ì„ ì´ìš©í•˜ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ Prediction ì•Œê³ ë¦¬ì¦˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start first visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:04<00:00, 23994.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.80      |      -4.01      |      -3.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.00      |      -3.90      |      -2.41      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.46      |      -2.46      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n",
      "start every visit MC\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:04<00:00, 24056.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V(s)\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.80      |      -4.01      |      -3.44      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -4.00      |      -3.90      |      -2.41      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "|                 |                 |                 |\n",
      "|      -3.45      |      -2.44      |       1.00      |\n",
      "|                 |                 |                 |\n",
      "+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Incremental mean ì„ ì´ìš©í•˜ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ Prediction ì•Œê³ ë¦¬ì¦˜\n",
    "np.random.seed(0)\n",
    "\n",
    "# í™˜ê²½, ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "# ì„ì˜ì˜ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ğ‘‰\n",
    "v_table = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ì¶”ê°€\n",
    "# ìƒíƒœë¥¼ ë°©ë¬¸í•œ íšŸìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”\n",
    "v_visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "\n",
    "# ì‚­ì œ\n",
    "# # ğ‘…ğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›(ğ‘ )â†ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  sâˆˆğ‘†ì— ëŒ€í•´) : \n",
    "# Return_s = [[[] for j in range(env.reward.shape[1])] for i in range(env.reward.shape[0])]\n",
    "\n",
    "# ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ì™€ ì—í”¼ì†Œë“œ ìµœëŒ€ ê¸¸ì´ì§€ì •\n",
    "max_episode = 100000\n",
    "\n",
    "# first visitì„ ì‚¬ìš©í• ì§€ every visitì„ ì‚¬ìš©í•  ì§€ ê²°ì •\n",
    "# first_visit = True : first visit\n",
    "# first_visit = False : every visit\n",
    "\n",
    "for first_visit in [True, False]:\n",
    "    if first_visit:\n",
    "        print(\"start first visit MC\")\n",
    "    else : \n",
    "        print(\"start every visit MC\")\n",
    "    print()\n",
    "\n",
    "    for epi in tqdm(range(max_episode)):\n",
    "\n",
    "        i,j,G,episode = generate_episode(env, agent, first_visit)\n",
    "\n",
    "        visit = np.zeros((env.reward.shape[0], env.reward.shape[1]))\n",
    "        v_start[i,j] += 1\n",
    "        \n",
    "        for where, action, reward, G_s in episode:\n",
    "            s_i, s_j = where\n",
    "            if first_visit and visit[s_i][s_j] == 1:\n",
    "                continue\n",
    "            visit[s_i][s_j] = 1\n",
    "\n",
    "            v_visit[s_i,s_j] += 1\n",
    "            v_table[s_i,s_j] += 1 / v_visit[s_i,s_j] * (G_s - v_table[s_i,s_j])\n",
    "\n",
    "    print(\"V(s)\")\n",
    "    show_v_table(np.round(v_table,2),env)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ì•ì˜ ì—í”¼ì†Œë“œ ìƒì„±í•¨ìˆ˜ 'generate_episode' í•¨ìˆ˜ì—ì„œ i, j ê°’ì„ 0ìœ¼ë¡œ ì§€ì •í•´ì£¼ê³  ì½”ë“œ ëŒë¦¬ê¸°`\n",
    "\n",
    "\n",
    "* ê²°ê³¼ì ìœ¼ë¡œ, ì—í”¼ì†Œë“œì˜ ìˆ˜ê°€ ì ì  ì¤„ì–´ë“¤ì§€ë§Œ, ìƒíƒœê°€ì¹˜ê°€ ì»¤ì§€ëŠ” í˜•íƒœê°€ ê±°ì˜ ë™ì¼\n",
    "    - íš¨ìœ¨ì ì¸ ê³„ì‚° ê°€ëŠ¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
